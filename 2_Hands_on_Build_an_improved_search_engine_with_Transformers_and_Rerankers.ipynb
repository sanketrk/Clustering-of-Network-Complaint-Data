{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanketrk/Clustering-of-Network-Complaint-Data/blob/master/2_Hands_on_Build_an_improved_search_engine_with_Transformers_and_Rerankers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVemECCPfYg0"
      },
      "source": [
        "# Improved Question-Answering Search Engines with Transformers and Rerankers\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/7SXKckD.png)\n",
        "\n",
        "Transfer Learning is the power of leveraging already trained models and tune \\ adapt them to our own downstream tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA Search Engine using Transformers"
      ],
      "metadata": {
        "id": "WtItCuV_2x8D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHruWvqUgO-x"
      },
      "source": [
        "## Retrival and Re-ranking\n",
        "\n",
        "In Semantic Search we have shown how to use SentenceTransformer to compute embeddings for queries, sentences, and paragraphs and how to use this for semantic search.\n",
        "\n",
        "For complex search tasks, for example, for question answering retrieval, the search can significantly be improved by using Retrieve & Re-Rank.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRDuVi6fgsSM"
      },
      "source": [
        "## Retrieve & Re-Rank Pipeline\n",
        "\n",
        "A pipeline for information retrieval / question answering retrieval that works well is the following. All components are provided and explained in this notebook:\n",
        "\n",
        "![](https://i.imgur.com/yIXJRSo.png)\n",
        "\n",
        "\n",
        "Given a search query, we first use a retrieval system that retrieves a large list of e.g. 100 possible hits which are potentially relevant for the query.\n",
        "For the retrieval, we can use either lexical search, e.g. with ElasticSearch, or we can use dense retrieval with a bi-encoder. Simple Lexical searches can be based on TF-IDF, BM25 etc.\n",
        "\n",
        "\n",
        "However, the retrieval system might retrieve documents that are not that relevant for the search query.\n",
        "Hence, in a second stage, we use a re-ranker based on a cross-encoder that scores the relevancy of all candidates for the given search query.\n",
        "\n",
        "The output will be a ranked list of hits we can present to the user.\n",
        "\n",
        "\n",
        "## Retrieval: Bi-Encoder\n",
        "\n",
        "For the retrieval of the candidate set, we can either use lexical search (e.g. ElasticSearch), or we can use a bi-encoder (semantic search) which is implemented in this repository.\n",
        "\n",
        "Lexical search looks for literal matches of the query words in your document collection. It will not recognize synonyms, acronyms or spelling variations.\n",
        "\n",
        "In contrast, semantic search (or dense retrieval) encodes the search query into vector space and retrieves the document embeddings that are close in vector space.\n",
        "\n",
        "Bi-Encoders produce for a given sentence or document an embedding.\n",
        "\n",
        "\n",
        "## Re-Ranker: Cross-Encoder\n",
        "\n",
        "The retriever has to be efficient for large document collections with millions of entries. However, it might return irrelevant candidates.\n",
        "\n",
        "A re-ranker based on a Cross-Encoder can substantially improve the final results for the user. The query and a possible document is passed simultaneously to transformer network, which then outputs a single score between 0 and 1 indicating how relevant the document is for the given query.\n",
        "\n",
        "![](https://i.imgur.com/PFgkrcI.png)\n",
        "\n",
        "The advantage of Cross-Encoders is the higher performance, as they perform attention across the query and the document.\n",
        "\n",
        "Scoring thousands or millions of (query, document)-pairs would be rather slow. Hence, we use the retriever to create a set of e.g. 100 possible candidates which are then re-ranked by the Cross-Encoder.\n",
        "\n",
        "First, you use an efficient Bi-Encoder to retrieve e.g. the top-100 most similar sentences for a query. Then, you use a Cross-Encoder to re-rank these 100 hits by computing the score for every (query, hit) combination.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve & Re-Rank Search Engine over Simple Wikipedia\n",
        "\n",
        "This examples demonstrates the Retrieve & Re-Rank Setup and allows to search over Simple Wikipedia.\n",
        "\n",
        "You can input a query or a question. The script then uses semantic search to find relevant passages in Simple English Wikipedia\n",
        "\n",
        "___[Created By: Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___"
      ],
      "metadata": {
        "id": "PRd8SWrgO6J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "kLM0sIdwulHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies"
      ],
      "metadata": {
        "id": "2uHHJWeD265r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "yNPXLaZdvSNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Transformer Models, Wikipedia Data and Generate Embeddings"
      ],
      "metadata": {
        "id": "XtLOFNhf2_23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For semantic search, we use `SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')` and retrieve 32 potentially relevant passages that answer the input query.\n",
        "\n",
        "Next, we use a more powerful CrossEncoder `(cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2'))` that scores the query and all retrieved passages for their relevancy. The cross-encoder further boost the performance."
      ],
      "metadata": {
        "id": "JBjYoy6jPSS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MS MARCO is a large scale information retrieval corpus that was created based on real user search queries using Bing search engine.\n",
        "\n",
        "The provided models can be used for semantic search, i.e., given keywords / a search phrase / a question, the model will find passages that are relevant for the search query."
      ],
      "metadata": {
        "id": "QaqySmO4TylU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Wikipedia Dataset"
      ],
      "metadata": {
        "id": "XFt1QsWQ4Zve"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwM52iwoJTtN"
      },
      "source": [
        "import json\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "import gzip\n",
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "# As dataset, we use Simple English Wikipedia. Compared to the full English wikipedia, it has only\n",
        "# about 170k articles. We split these articles into paragraphs and encode them with the bi-encoder\n",
        "\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "\n",
        "if not os.path.exists(wikipedia_filepath):\n",
        "    util.http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)\n",
        "\n",
        "passages = []\n",
        "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        data = json.loads(line.strip())\n",
        "\n",
        "        #Add all paragraphs\n",
        "        #passages.extend(data['paragraphs'])\n",
        "\n",
        "        #Only add the first paragraph\n",
        "        passages.append(data['paragraphs'][0])\n",
        "\n",
        "print(\"Passages:\", len(passages))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subset Dataset"
      ],
      "metadata": {
        "id": "c5qMEitB4cNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We subset our data so we only use a subset of wikipedia to run things faster\n",
        "\n",
        "passages = [passage for passage in passages for x in ['india', 'north pole', 'nlp',\n",
        "                                                      'natural language processing', 'linguistics',\n",
        "                                                      'machine learning', 'artificial intelligence',\n",
        "                                                      'cheetah', 'animal', 'jaguar']\n",
        "                                                    if x in passage.lower()]"
      ],
      "metadata": {
        "id": "uOCU_LPvkYjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at sample documents"
      ],
      "metadata": {
        "id": "ebcS_xSW4gi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(passages)"
      ],
      "metadata": {
        "id": "M0E1hpJkpKCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0]"
      ],
      "metadata": {
        "id": "z22WY53WDKUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Transformer Models"
      ],
      "metadata": {
        "id": "xDEs8fYq4jWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning: No GPU found. Please add GPU to your notebook\")\n",
        "\n",
        "\n",
        "# We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n",
        "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "# The bi-encoder will retrieve 100 documents.\n",
        "# We use a cross-encoder, to re-rank the results list to improve the quality\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "id": "LqDPyPoWi8WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Wikipedia Document Embeddings"
      ],
      "metadata": {
        "id": "HzvlgSPm4nI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We encode all passages into our vector space. This takes about few seconds (depends on your GPU speed)\n",
        "corpus_embeddings ="
      ],
      "metadata": {
        "id": "4zFWjfzZv0-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0]"
      ],
      "metadata": {
        "id": "BHxNAZBwvKxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings[0], corpus_embeddings[0].shape"
      ],
      "metadata": {
        "id": "4ziXj6zEvc4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Search with a Sample Query"
      ],
      "metadata": {
        "id": "7LIcIyC94uRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New Query"
      ],
      "metadata": {
        "id": "Jzk6CYnU417l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the capital of India?\"\n",
        "query"
      ],
      "metadata": {
        "id": "3cRGIl8Yw4ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Embedding for New Query"
      ],
      "metadata": {
        "id": "U6pcQDsx43Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding =\n",
        "query_embedding.shape"
      ],
      "metadata": {
        "id": "xwhIDF-gw9k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Cosine Similarity Score of Document Emebddings compared to New Query Embedding"
      ],
      "metadata": {
        "id": "w6NG_5a446VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_scores =\n",
        "cos_scores"
      ],
      "metadata": {
        "id": "wrmSbShhxGvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Most Similar Document ID"
      ],
      "metadata": {
        "id": "NfSrRpZa4-Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_results =\n",
        "idx =\n",
        "idx"
      ],
      "metadata": {
        "id": "M3vk3iDuxQVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Most Similar Document"
      ],
      "metadata": {
        "id": "P4KPaUyB5Bs8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3CcNjr3DxV2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternate way of getting most similar document"
      ],
      "metadata": {
        "id": "HFxgayNF5KRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=1)\n",
        "hits[0]"
      ],
      "metadata": {
        "id": "2pHl-H94xegI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hits[0][0]['corpus_id']"
      ],
      "metadata": {
        "id": "wuHmGUUwxzQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bi Encoder + ReRanker Cross Encoder Search"
      ],
      "metadata": {
        "id": "SnyFZYP85Q5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get top K Similar documents from Bi-encoder and format input data for Reranker Cross-encoder"
      ],
      "metadata": {
        "id": "_O0ryeAC5nwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 30 similar documents (hits) to the query\n",
        "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=30)\n",
        "hits = hits[0]\n",
        "# Format data for the reranker -> [query, similar_doc] for each of the top_k similar documents\n",
        "reranker_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n",
        "reranker_inp[:3] # look at the first 3 query inputs to the reranker cross encoder model"
      ],
      "metadata": {
        "id": "pL2kV-LvyMIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Reranker score for every similar document"
      ],
      "metadata": {
        "id": "oNa6qBd45m0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reranker_scores = cross_encoder.predict(reranker_inp)\n",
        "reranker_scores[:3] # look at relevance scores from reranker cross encoder"
      ],
      "metadata": {
        "id": "8qfY2V-YyhqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Reranker score back to the hits dictionary"
      ],
      "metadata": {
        "id": "i6EvbWEt50u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hits[:3]"
      ],
      "metadata": {
        "id": "OI9WQNRhyfTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id, hit in enumerate(hits):\n",
        "    hit['reranker_score'] = reranker_scores[id]\n",
        "hits[:3]"
      ],
      "metadata": {
        "id": "OZqC-TkAy1Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show the top similar document to query based on both models"
      ],
      "metadata": {
        "id": "J5Dh257c58LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top Bi-Encoder Retrieval hit: \")\n",
        "hit = sorted(hits, key=lambda x: x['score'], reverse=True)[0]\n",
        "print(passages[hit['corpus_id']])\n",
        "\n",
        "print(\"Top Reranker Retrieval hit: \")\n",
        "hit = sorted(hits, key=lambda x: x['reranker_score'], reverse=True)[0]\n",
        "print(passages[hit['corpus_id']])"
      ],
      "metadata": {
        "id": "qsP2GOC3zLWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a function to return the top similar document based on any query"
      ],
      "metadata": {
        "id": "gG2k_-onQ8iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query, top_k=30):\n",
        "  # print the input question\n",
        "\n",
        "\n",
        "  ##### Bi-Encoder: Sematic Search #####\n",
        "  # Encode the query using the bi-encoder and find potentially relevant passages\n",
        "\n",
        "\n",
        "  ##### Cross-Encoder: Re-Ranking #####\n",
        "  # Now, score all retrieved passages with the reranker cross encoder\n",
        "\n",
        "\n",
        "  # Store reranker cross encoder scores back into the hits variable\n",
        "\n",
        "\n",
        "  # Output of top-1 hit from bi-encoder\n",
        "\n",
        "\n",
        "  # Output of top-1 hit from re-ranker\n"
      ],
      "metadata": {
        "id": "nNiEVhpaKH2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try out the function"
      ],
      "metadata": {
        "id": "dksEmCgw6GOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is the capital of India?\")"
      ],
      "metadata": {
        "id": "V9qrnl8DmbFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is natural language processing?\")"
      ],
      "metadata": {
        "id": "syaODja7SQEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is language?\")"
      ],
      "metadata": {
        "id": "cAhF2d1HZDSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is coldest place on earth?\")"
      ],
      "metadata": {
        "id": "8dATCBKJ2eYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is the animal which can run very fast?\")"
      ],
      "metadata": {
        "id": "QtY_OjzT2pGC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}