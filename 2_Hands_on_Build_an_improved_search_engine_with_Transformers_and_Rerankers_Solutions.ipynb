{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "521370a128894a92bb05e7455bd63139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4590a60b390d418185ceefe815dd48fc",
              "IPY_MODEL_207c52a6bb804747952c855658086b06",
              "IPY_MODEL_6f6c7311e14f4f94a561b88c917bff8f"
            ],
            "layout": "IPY_MODEL_83543ec237a94c28886b87cae7fbf6ad"
          }
        },
        "4590a60b390d418185ceefe815dd48fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0179e064bc904b719d6c66557a409748",
            "placeholder": "​",
            "style": "IPY_MODEL_0118f0a8534c49b6baa55c800c825ba9",
            "value": "Batches: 100%"
          }
        },
        "207c52a6bb804747952c855658086b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ced1d76b9747fab2675cd4fa34e765",
            "max": 185,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_377d3f98841f4a6d9969d90f008eeecb",
            "value": 185
          }
        },
        "6f6c7311e14f4f94a561b88c917bff8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47ac2629ddf34518b707bbf6f54c0428",
            "placeholder": "​",
            "style": "IPY_MODEL_f8cd1f6d6fa84435b367ba815d67b5a5",
            "value": " 185/185 [00:06&lt;00:00, 52.35it/s]"
          }
        },
        "83543ec237a94c28886b87cae7fbf6ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0179e064bc904b719d6c66557a409748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0118f0a8534c49b6baa55c800c825ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4ced1d76b9747fab2675cd4fa34e765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377d3f98841f4a6d9969d90f008eeecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47ac2629ddf34518b707bbf6f54c0428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cd1f6d6fa84435b367ba815d67b5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanketrk/Clustering-of-Network-Complaint-Data/blob/master/2_Hands_on_Build_an_improved_search_engine_with_Transformers_and_Rerankers_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVemECCPfYg0"
      },
      "source": [
        "# Improved Question-Answering Search Engines with Transformers and Rerankers\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/7SXKckD.png)\n",
        "\n",
        "Transfer Learning is the power of leveraging already trained models and tune \\ adapt them to our own downstream tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA Search Engine using Transformers"
      ],
      "metadata": {
        "id": "WtItCuV_2x8D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHruWvqUgO-x"
      },
      "source": [
        "## Retrival and Re-ranking\n",
        "\n",
        "In Semantic Search we have shown how to use SentenceTransformer to compute embeddings for queries, sentences, and paragraphs and how to use this for semantic search.\n",
        "\n",
        "For complex search tasks, for example, for question answering retrieval, the search can significantly be improved by using Retrieve & Re-Rank.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRDuVi6fgsSM"
      },
      "source": [
        "## Retrieve & Re-Rank Pipeline\n",
        "\n",
        "A pipeline for information retrieval / question answering retrieval that works well is the following. All components are provided and explained in this notebook:\n",
        "\n",
        "![](https://i.imgur.com/yIXJRSo.png)\n",
        "\n",
        "\n",
        "Given a search query, we first use a retrieval system that retrieves a large list of e.g. 100 possible hits which are potentially relevant for the query.\n",
        "For the retrieval, we can use either lexical search, e.g. with ElasticSearch, or we can use dense retrieval with a bi-encoder. Simple Lexical searches can be based on TF-IDF, BM25 etc.\n",
        "\n",
        "\n",
        "However, the retrieval system might retrieve documents that are not that relevant for the search query.\n",
        "Hence, in a second stage, we use a re-ranker based on a cross-encoder that scores the relevancy of all candidates for the given search query.\n",
        "\n",
        "The output will be a ranked list of hits we can present to the user.\n",
        "\n",
        "\n",
        "## Retrieval: Bi-Encoder\n",
        "\n",
        "For the retrieval of the candidate set, we can either use lexical search (e.g. ElasticSearch), or we can use a bi-encoder (semantic search) which is implemented in this repository.\n",
        "\n",
        "Lexical search looks for literal matches of the query words in your document collection. It will not recognize synonyms, acronyms or spelling variations.\n",
        "\n",
        "In contrast, semantic search (or dense retrieval) encodes the search query into vector space and retrieves the document embeddings that are close in vector space.\n",
        "\n",
        "Bi-Encoders produce for a given sentence or document an embedding.\n",
        "\n",
        "\n",
        "## Re-Ranker: Cross-Encoder\n",
        "\n",
        "The retriever has to be efficient for large document collections with millions of entries. However, it might return irrelevant candidates.\n",
        "\n",
        "A re-ranker based on a Cross-Encoder can substantially improve the final results for the user. The query and a possible document is passed simultaneously to transformer network, which then outputs a single score between 0 and 1 indicating how relevant the document is for the given query.\n",
        "\n",
        "![](https://i.imgur.com/PFgkrcI.png)\n",
        "\n",
        "The advantage of Cross-Encoders is the higher performance, as they perform attention across the query and the document.\n",
        "\n",
        "Scoring thousands or millions of (query, document)-pairs would be rather slow. Hence, we use the retriever to create a set of e.g. 100 possible candidates which are then re-ranked by the Cross-Encoder.\n",
        "\n",
        "First, you use an efficient Bi-Encoder to retrieve e.g. the top-100 most similar sentences for a query. Then, you use a Cross-Encoder to re-rank these 100 hits by computing the score for every (query, hit) combination.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve & Re-Rank Search Engine over Simple Wikipedia\n",
        "\n",
        "This examples demonstrates the Retrieve & Re-Rank Setup and allows to search over Simple Wikipedia.\n",
        "\n",
        "You can input a query or a question. The script then uses semantic search to find relevant passages in Simple English Wikipedia\n",
        "\n",
        "___[Created By: Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___"
      ],
      "metadata": {
        "id": "PRd8SWrgO6J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLM0sIdwulHC",
        "outputId": "6fb62e1d-8bf1-49bf-ace9-480b1bdd4699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 13 21:33:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies"
      ],
      "metadata": {
        "id": "2uHHJWeD265r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNPXLaZdvSNt",
        "outputId": "a53c8b1a-32ec-493e-c449-baa33e186345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/156.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m122.9/156.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Transformer Models, Wikipedia Data and Generate Embeddings"
      ],
      "metadata": {
        "id": "XtLOFNhf2_23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For semantic search, we use `SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')` and retrieve 32 potentially relevant passages that answer the input query.\n",
        "\n",
        "Next, we use a more powerful CrossEncoder `(cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2'))` that scores the query and all retrieved passages for their relevancy. The cross-encoder further boost the performance."
      ],
      "metadata": {
        "id": "JBjYoy6jPSS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MS MARCO is a large scale information retrieval corpus that was created based on real user search queries using Bing search engine.\n",
        "\n",
        "The provided models can be used for semantic search, i.e., given keywords / a search phrase / a question, the model will find passages that are relevant for the search query."
      ],
      "metadata": {
        "id": "QaqySmO4TylU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Wikipedia Dataset"
      ],
      "metadata": {
        "id": "XFt1QsWQ4Zve"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwM52iwoJTtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75953779-28bd-44f4-8bd5-8f36578fbab7"
      },
      "source": [
        "import json\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "import gzip\n",
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "# As dataset, we use Simple English Wikipedia. Compared to the full English wikipedia, it has only\n",
        "# about 170k articles. We split these articles into paragraphs and encode them with the bi-encoder\n",
        "\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "\n",
        "if not os.path.exists(wikipedia_filepath):\n",
        "    util.http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', wikipedia_filepath)\n",
        "\n",
        "passages = []\n",
        "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        data = json.loads(line.strip())\n",
        "\n",
        "        #Add all paragraphs\n",
        "        #passages.extend(data['paragraphs'])\n",
        "\n",
        "        #Only add the first paragraph\n",
        "        passages.append(data['paragraphs'][0])\n",
        "\n",
        "print(\"Passages:\", len(passages))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passages: 169597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subset Dataset"
      ],
      "metadata": {
        "id": "c5qMEitB4cNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We subset our data so we only use a subset of wikipedia to run things faster\n",
        "\n",
        "passages = [passage for passage in passages for x in ['india', 'north pole', 'nlp',\n",
        "                                                      'natural language processing', 'linguistics',\n",
        "                                                      'machine learning', 'artificial intelligence',\n",
        "                                                      'cheetah', 'animal', 'jaguar']\n",
        "                                                    if x in passage.lower()]"
      ],
      "metadata": {
        "id": "uOCU_LPvkYjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at sample documents"
      ],
      "metadata": {
        "id": "ebcS_xSW4gi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(passages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0E1hpJkpKCE",
        "outputId": "f8330ffb-8aa6-45a9-d449-40600aa377d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5917"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "z22WY53WDKUD",
        "outputId": "11c3509c-618a-43dc-9034-262379b4c81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The integumentary system is everything covering the outside of an animal's body. This account is written mostly with people in mind, but it applies more widely.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Transformer Models"
      ],
      "metadata": {
        "id": "xDEs8fYq4jWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not torch.cuda.is_available():\n",
        "    print(\"Warning: No GPU found. Please add GPU to your notebook\")\n",
        "\n",
        "\n",
        "# We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n",
        "bi_encoder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "# The bi-encoder will retrieve 100 documents.\n",
        "# We use a cross-encoder, to re-rank the results list to improve the quality\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "id": "LqDPyPoWi8WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Wikipedia Document Embeddings"
      ],
      "metadata": {
        "id": "HzvlgSPm4nI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We encode all passages into our vector space. This takes about few seconds (depends on your GPU speed)\n",
        "corpus_embeddings = bi_encoder.encode(passages, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "521370a128894a92bb05e7455bd63139",
            "4590a60b390d418185ceefe815dd48fc",
            "207c52a6bb804747952c855658086b06",
            "6f6c7311e14f4f94a561b88c917bff8f",
            "83543ec237a94c28886b87cae7fbf6ad",
            "0179e064bc904b719d6c66557a409748",
            "0118f0a8534c49b6baa55c800c825ba9",
            "f4ced1d76b9747fab2675cd4fa34e765",
            "377d3f98841f4a6d9969d90f008eeecb",
            "47ac2629ddf34518b707bbf6f54c0428",
            "f8cd1f6d6fa84435b367ba815d67b5a5"
          ]
        },
        "id": "4zFWjfzZv0-k",
        "outputId": "593c9c73-1252-4bcf-e220-dd0b7c112ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/185 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "521370a128894a92bb05e7455bd63139"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passages[0]"
      ],
      "metadata": {
        "id": "BHxNAZBwvKxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "02d1edf6-04e9-46c8-a43e-e08432260995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The integumentary system is everything covering the outside of an animal's body. This account is written mostly with people in mind, but it applies more widely.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_embeddings[0], corpus_embeddings[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ziXj6zEvc4Y",
        "outputId": "0a73981a-d367-4aa8-ac6b-bc89e1d42487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 2.43610446e-03,  3.29437926e-02,  4.70606014e-02, -7.68167479e-03,\n",
              "         1.48560539e-01, -7.82975107e-02,  2.99415477e-02,  1.36641292e-02,\n",
              "         1.53808743e-02,  1.40475079e-01,  2.35609505e-02, -8.67463648e-02,\n",
              "         2.46762913e-02,  8.08474980e-03, -1.67811643e-02, -6.50802329e-02,\n",
              "        -3.48654017e-02, -7.70691840e-04, -5.02524003e-02,  7.39627331e-03,\n",
              "        -2.48694886e-02,  6.15889803e-02, -2.88300738e-02,  8.74973182e-03,\n",
              "        -1.11718066e-01, -3.45828454e-03, -4.96662334e-02, -5.51604889e-02,\n",
              "        -3.83206941e-02, -6.52881041e-02, -4.57847957e-03, -4.55709547e-02,\n",
              "         5.72044179e-02,  3.42551805e-02, -4.65118140e-03, -2.70470697e-02,\n",
              "         3.08932122e-02, -2.60512847e-02, -5.11268862e-02,  3.61177027e-02,\n",
              "         7.31430808e-03,  2.07178947e-02,  2.00569984e-02,  2.59086005e-02,\n",
              "         8.13343152e-02,  4.40371670e-02, -1.29732475e-01, -6.40622452e-02,\n",
              "         8.23869649e-03, -3.58666468e-04,  7.39453956e-02, -4.48799320e-02,\n",
              "        -4.20405269e-02,  1.27976477e-01, -6.04274385e-02, -1.40302666e-02,\n",
              "        -6.02459647e-02,  6.14528060e-02, -7.21564740e-02, -6.34479672e-02,\n",
              "         1.63977310e-01, -1.68563742e-02,  3.15048434e-02,  5.09586930e-02,\n",
              "        -9.02756024e-03, -2.67425049e-02,  1.06029157e-02,  1.00399949e-01,\n",
              "        -4.73300405e-02, -9.24934670e-02, -1.21589489e-02, -1.82155687e-02,\n",
              "        -8.66573155e-02, -1.60982516e-02, -1.76461302e-02, -2.65020113e-02,\n",
              "         3.43781412e-02,  1.46792214e-02,  6.63821474e-02,  3.73618305e-02,\n",
              "         2.17691734e-02,  1.00291349e-01,  2.66134441e-02,  4.78912480e-02,\n",
              "        -4.08197381e-03,  2.24307775e-02, -5.66577911e-02,  2.08289288e-02,\n",
              "        -1.55685367e-02, -5.86488806e-02,  2.05983687e-02, -6.29677102e-02,\n",
              "         3.20426822e-02, -2.79935207e-02,  7.77789429e-02,  1.39769083e-02,\n",
              "        -6.84900256e-03, -5.01475483e-02,  2.82515958e-02, -8.46940465e-03,\n",
              "        -3.58295366e-02, -8.47698674e-02,  3.42259072e-02,  1.22650294e-02,\n",
              "         4.06868607e-02, -7.14107528e-02, -1.93590149e-02,  3.49872038e-02,\n",
              "         6.11166656e-02,  1.53532997e-02, -3.71368900e-02, -5.19964471e-02,\n",
              "        -2.31725574e-02,  5.65126203e-02,  3.91082987e-02, -2.85687968e-02,\n",
              "         4.14784774e-02,  2.13866476e-02,  9.11964327e-02, -5.40107675e-02,\n",
              "         1.05727213e-02, -7.73281371e-03,  3.45059787e-03, -9.95285343e-04,\n",
              "         4.29395214e-02,  1.54650947e-02,  6.49399459e-02,  4.45449917e-31,\n",
              "        -5.38449101e-02, -9.58033353e-02,  5.47166802e-02,  9.78533179e-03,\n",
              "        -3.55320275e-02, -1.47581147e-02, -5.94028225e-03, -9.81630199e-03,\n",
              "         3.49594578e-02,  1.97602771e-02, -4.68775108e-02,  5.19975796e-02,\n",
              "         2.11553797e-02,  1.50061399e-01,  5.31986989e-02,  5.14656082e-02,\n",
              "        -5.60685731e-02,  8.53513032e-02,  1.02747835e-01, -3.92962852e-03,\n",
              "         6.39218884e-03,  3.77836227e-02,  4.67668511e-02, -6.73896149e-02,\n",
              "         1.12430654e-01,  1.65198930e-02, -8.75122771e-02, -1.16442554e-01,\n",
              "        -1.79986618e-02, -1.95271466e-02,  1.34201124e-02,  1.12787727e-03,\n",
              "        -4.33416478e-02,  2.60387715e-02, -4.46670204e-02, -3.22980359e-02,\n",
              "         8.27495530e-02, -5.10384962e-02, -4.72272077e-04, -7.95203894e-02,\n",
              "         4.43114154e-02, -2.02918034e-02,  1.25103027e-01, -8.11163038e-02,\n",
              "         7.86774084e-02,  5.03847003e-02,  5.11074089e-04,  6.94201980e-03,\n",
              "         1.12292171e-02,  2.72419048e-03,  4.70597148e-02,  5.49497642e-02,\n",
              "         1.04190856e-01, -1.05369583e-01, -4.15502004e-02,  6.87612891e-02,\n",
              "         2.20433213e-02,  7.81628769e-03, -1.47707164e-01,  3.31715192e-03,\n",
              "        -3.46318877e-04,  2.51039024e-02,  7.19455183e-02, -7.00906385e-03,\n",
              "         7.87859261e-02, -3.37422118e-02, -1.14436150e-01, -3.08879223e-02,\n",
              "         2.75238585e-02,  2.35665534e-02, -7.28548244e-02, -4.61692698e-02,\n",
              "         1.37734483e-03,  1.02663087e-02,  3.65370810e-02,  6.66310452e-03,\n",
              "        -2.88746078e-02, -4.83899489e-02, -9.27790403e-02,  3.16815749e-02,\n",
              "        -6.58158436e-02,  3.49000469e-02, -3.23607810e-02,  2.10270956e-02,\n",
              "         3.43543217e-02,  5.57590500e-02, -1.42314434e-02,  7.57350549e-02,\n",
              "         3.27625945e-02, -1.01992674e-01,  2.27971077e-02, -2.59552877e-02,\n",
              "        -4.62757796e-02,  4.35848609e-02, -3.97642702e-02, -4.05773340e-33,\n",
              "         3.81920189e-02, -1.05362698e-01, -2.20380388e-02,  2.97885370e-02,\n",
              "        -2.45153648e-03,  4.33552042e-02, -2.27318555e-02,  1.45082790e-02,\n",
              "         4.20105569e-02,  9.36221518e-03,  3.20281722e-02,  7.70531669e-02,\n",
              "        -1.69117711e-02, -1.32985711e-02,  1.82859488e-02,  5.13907569e-03,\n",
              "        -1.07534692e-01, -4.93955314e-02,  2.01356653e-02, -3.98332849e-02,\n",
              "        -5.22080325e-02,  2.45556682e-02,  7.07008839e-02, -4.38241707e-03,\n",
              "        -4.19728234e-02, -1.56250596e-02, -5.04878089e-02, -3.34509276e-02,\n",
              "        -1.91044398e-02, -5.50474226e-02, -4.45643812e-02, -6.57841051e-03,\n",
              "        -1.46685522e-02, -2.06549112e-02, -4.73629162e-02, -3.70257646e-02,\n",
              "         2.24751625e-02, -4.19191234e-02, -1.06052116e-01, -2.57355142e-02,\n",
              "        -2.94116475e-02,  4.82965028e-03, -3.32664289e-02, -4.55640331e-02,\n",
              "        -9.03126411e-03,  1.24873128e-02, -6.19083904e-02,  2.20663138e-02,\n",
              "        -6.61915839e-02, -2.87703308e-03, -6.37556762e-02, -8.15871544e-03,\n",
              "         3.97671200e-02,  1.68448910e-02,  2.30698623e-02,  5.74797392e-02,\n",
              "         2.51442175e-02,  6.63422123e-02, -2.29850906e-04,  5.14069796e-02,\n",
              "         1.29240807e-02, -6.29302580e-03, -4.45461608e-02, -4.30534258e-02,\n",
              "        -5.20174988e-02, -3.03082634e-03, -4.40474786e-02, -3.17821279e-02,\n",
              "        -2.17197519e-02, -5.90047240e-02,  9.44999680e-02, -1.50923617e-02,\n",
              "        -1.87748875e-02, -3.49902771e-02,  3.18811238e-02,  5.84906936e-02,\n",
              "         1.20628029e-01, -1.17227033e-01,  5.01899282e-03, -1.96520910e-02,\n",
              "        -7.43321776e-02, -9.70055535e-02,  1.19245406e-02,  2.71050017e-02,\n",
              "         1.22754715e-01, -5.06423116e-02, -7.74042010e-02, -2.62956470e-02,\n",
              "         2.18954273e-02, -1.36604207e-02, -6.77243397e-02,  1.21797603e-02,\n",
              "        -4.90854830e-02,  5.08677326e-02,  5.32611832e-03, -4.87410761e-33,\n",
              "         1.37023017e-01,  1.18652144e-02,  6.47499925e-03, -4.73829135e-02,\n",
              "        -4.86396514e-02, -6.59691682e-03, -1.95316199e-04,  4.55547981e-02,\n",
              "         4.78984509e-03,  8.90175030e-02,  3.97000462e-03, -1.38619747e-02,\n",
              "         5.46483435e-02,  1.25777675e-02,  7.07946941e-02,  3.90802436e-02,\n",
              "        -3.63910040e-05,  1.74267888e-02, -2.01984104e-02, -7.25744152e-03,\n",
              "        -3.48305749e-03, -2.04696245e-02, -8.80882815e-02, -2.49504577e-02,\n",
              "         9.90878791e-02, -1.03035299e-02, -3.48453932e-02, -1.69981681e-02,\n",
              "        -9.61551256e-03,  6.26932830e-02, -1.82569623e-02, -1.64299656e-03,\n",
              "        -3.57449688e-02,  6.22679852e-02,  1.59737580e-02,  7.59656057e-02,\n",
              "         5.99773861e-02,  2.50788173e-03,  5.10130674e-02,  1.01512892e-03,\n",
              "         5.31041846e-02, -5.96369710e-03,  2.25312561e-02,  5.04157366e-03,\n",
              "         3.35895605e-02,  2.94236317e-02,  9.71813574e-02,  4.15868945e-02,\n",
              "         2.80859191e-02, -1.40969976e-04, -3.19713056e-02, -1.80652160e-02,\n",
              "        -4.20634933e-02, -4.81352657e-02, -5.47631197e-02,  1.97499152e-02,\n",
              "        -2.00341474e-02, -5.81272915e-02,  4.57191989e-02,  4.71159369e-02,\n",
              "         7.63628585e-03,  2.14010086e-02, -1.72026958e-02, -5.03396336e-03],\n",
              "       dtype=float32),\n",
              " (384,))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Search with a Sample Query"
      ],
      "metadata": {
        "id": "7LIcIyC94uRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New Query"
      ],
      "metadata": {
        "id": "Jzk6CYnU417l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the capital of India?\"\n",
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3cRGIl8Yw4ou",
        "outputId": "c5f3dea1-79e8-4807-dd6a-d8d211d6a0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the capital of India?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Embedding for New Query"
      ],
      "metadata": {
        "id": "U6pcQDsx43Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = bi_encoder.encode(query)\n",
        "query_embedding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwhIDF-gw9k1",
        "outputId": "0534e43e-7fcc-4616-8eef-1832df040596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(384,)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Cosine Similarity Score of Document Emebddings compared to New Query Embedding"
      ],
      "metadata": {
        "id": "w6NG_5a446VZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "cos_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrmSbShhxGvk",
        "outputId": "9bfc78a7-e88c-4f8e-d586-75f2fef2caf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0209, -0.0524,  0.2248,  ...,  0.1950, -0.1026,  0.3683])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Most Similar Document ID"
      ],
      "metadata": {
        "id": "NfSrRpZa4-Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_results = torch.topk(cos_scores, k=1)\n",
        "idx = top_results.indices.item()\n",
        "idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3vk3iDuxQVE",
        "outputId": "75bae001-c0bc-42aa-aade-752775b6f279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Most Similar Document"
      ],
      "metadata": {
        "id": "P4KPaUyB5Bs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passages[idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "3CcNjr3DxV2m",
        "outputId": "5203e796-ecd2-4bf2-9e0d-a218a282fe02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Mumbai (previously known as Bombay until 1996) is a natural harbor on the west coast of India, and is the capital city of Maharashtra state. It is India's largest city, and one of the world's most populous cities. It is the financial capital of India. The city is the second most-populous in the world. It has approximately 13 million people. Along with the neighboring cities of Navi Mumbai and Thane, it forms the world's 4th largest urban agglomeration. They have around 19.1 million people.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternate way of getting most similar document"
      ],
      "metadata": {
        "id": "HFxgayNF5KRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=1)\n",
        "hits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pHl-H94xegI",
        "outputId": "f7ee24a7-7e75-473b-8fb9-cf6204f3ef47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'corpus_id': 94, 'score': 0.5979240536689758}]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hits[0][0]['corpus_id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuHmGUUwxzQl",
        "outputId": "48bec0bb-aa14-4a2d-e561-744cba6e4dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bi Encoder + ReRanker Cross Encoder Search"
      ],
      "metadata": {
        "id": "SnyFZYP85Q5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get top K Similar documents from Bi-encoder and format input data for Reranker Cross-encoder"
      ],
      "metadata": {
        "id": "_O0ryeAC5nwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 30 similar documents (hits) to the query\n",
        "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=30)\n",
        "hits = hits[0]\n",
        "# Format data for the reranker -> [query, similar_doc] for each of the top_k similar documents\n",
        "reranker_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n",
        "reranker_inp[:3] # look at the first 3 query inputs to the reranker cross encoder model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL2kV-LvyMIC",
        "outputId": "20758624-594f-4edd-ca7f-f585744a9621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['What is the capital of India?',\n",
              "  \"Mumbai (previously known as Bombay until 1996) is a natural harbor on the west coast of India, and is the capital city of Maharashtra state. It is India's largest city, and one of the world's most populous cities. It is the financial capital of India. The city is the second most-populous in the world. It has approximately 13 million people. Along with the neighboring cities of Navi Mumbai and Thane, it forms the world's 4th largest urban agglomeration. They have around 19.1 million people.\"],\n",
              " ['What is the capital of India?',\n",
              "  \"Kolkata (spelled Calcutta before 1 January 2001) is the capital city of the Indian state of West Bengal. It is the second largest city in India after Mumbai. It is on the east bank of the River Hooghly. When it is called Calcutta, it includes the suburbs. This makes it the third largest city of India. This also makes it the world's 8th largest metropolitan area as defined by the United Nations. Kolkata served as the capital of India during the British Raj until 1911. Kolkata was once the center of industry and education. However, it has witnessed political violence and economic problems since 1954. Since 2000, Kolkata has grown due to economic growth. Like other metropolitan cities in India, Kolkata struggles with poverty, pollution and traffic congestion.\"],\n",
              " ['What is the capital of India?',\n",
              "  'Gandhinagar is the capital city of Gujarat state in India. It is 23\\xa0km from the city of Ahmedabad and 464\\xa0km from Mumbai. In the year 1960, the Bombay state of India was divided into two states - Maharashtra and Gujarat. Bombay (now called Mumbai) became the capital city of Maharashtra. For Gujarat, new capital was needed. Gandhinagar was then made the capital of Gujarat.']]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Reranker score for every similar document"
      ],
      "metadata": {
        "id": "oNa6qBd45m0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reranker_scores = cross_encoder.predict(reranker_inp)\n",
        "reranker_scores[:3] # look at relevance scores from reranker cross encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qfY2V-YyhqD",
        "outputId": "153848d9-ffc2-45cd-8db6-ac48e521ab2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.8610315, 3.4595225, 2.7084029], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Reranker score back to the hits dictionary"
      ],
      "metadata": {
        "id": "i6EvbWEt50u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hits[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI9WQNRhyfTN",
        "outputId": "32659ecd-3ec9-465b-c972-ef120b5a73c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'corpus_id': 94, 'score': 0.5979240536689758},\n",
              " {'corpus_id': 789, 'score': 0.5937108397483826},\n",
              " {'corpus_id': 4586, 'score': 0.5878058671951294}]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id, hit in enumerate(hits):\n",
        "    hit['reranker_score'] = reranker_scores[id]\n",
        "hits[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZqC-TkAy1Az",
        "outputId": "d6f73315-64a1-40bd-9533-6e2ebb86c8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'corpus_id': 94, 'score': 0.5979240536689758, 'reranker_score': 3.8610315},\n",
              " {'corpus_id': 789, 'score': 0.5937108397483826, 'reranker_score': 3.4595225},\n",
              " {'corpus_id': 4586, 'score': 0.5878058671951294, 'reranker_score': 2.7084029}]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show the top similar document to query based on both models"
      ],
      "metadata": {
        "id": "J5Dh257c58LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top Bi-Encoder Retrieval hit: \")\n",
        "hit = sorted(hits, key=lambda x: x['score'], reverse=True)[0]\n",
        "print(passages[hit['corpus_id']])\n",
        "\n",
        "print(\"Top Reranker Retrieval hit: \")\n",
        "hit = sorted(hits, key=lambda x: x['reranker_score'], reverse=True)[0]\n",
        "print(passages[hit['corpus_id']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsP2GOC3zLWC",
        "outputId": "b085df5e-0905-4308-f8f8-c77721b06145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Bi-Encoder Retrieval hit: \n",
            "Mumbai (previously known as Bombay until 1996) is a natural harbor on the west coast of India, and is the capital city of Maharashtra state. It is India's largest city, and one of the world's most populous cities. It is the financial capital of India. The city is the second most-populous in the world. It has approximately 13 million people. Along with the neighboring cities of Navi Mumbai and Thane, it forms the world's 4th largest urban agglomeration. They have around 19.1 million people.\n",
            "Top Reranker Retrieval hit: \n",
            "New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7 km. New Delhi has a population of about 9.4 Million people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a function to return the top similar document based on any query"
      ],
      "metadata": {
        "id": "gG2k_-onQ8iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query, top_k=30):\n",
        "  # print the input question\n",
        "  print(\"Input question:\", query)\n",
        "\n",
        "  ##### Bi-Encoder: Sematic Search #####\n",
        "  # Encode the query using the bi-encoder and find potentially relevant passages\n",
        "  question_embedding = bi_encoder.encode(query)\n",
        "  hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n",
        "  hits = hits[0]\n",
        "\n",
        "  ##### Cross-Encoder: Re-Ranking #####\n",
        "  # Now, score all retrieved passages with the reranker cross encoder\n",
        "  reranker_inp = [[query, passages[hit['corpus_id']]] for hit in hits]\n",
        "  reranker_scores = cross_encoder.predict(reranker_inp)\n",
        "\n",
        "  # Store reranker cross encoder scores back into the hits variable\n",
        "  for id, hit in enumerate(hits):\n",
        "    hit['reranker_score'] = reranker_scores[id]\n",
        "\n",
        "  # Output of top-1 hit from bi-encoder\n",
        "  print(\"\\n-------------------------\\n\")\n",
        "  print(\"Top Bi-Encoder Retrieval hit\")\n",
        "  hit = sorted(hits, key=lambda x: x['score'], reverse=True)[0]\n",
        "  print(passages[hit['corpus_id']])\n",
        "\n",
        "  # Output of top-1 hit from re-ranker\n",
        "  print(\"\\n-------------------------\\n\")\n",
        "  print(\"Top Cross-Encoder Re-ranker hit\")\n",
        "  hit = sorted(hits, key=lambda x: x['reranker_score'], reverse=True)[0]\n",
        "  print(passages[hit['corpus_id']])"
      ],
      "metadata": {
        "id": "nNiEVhpaKH2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try out the function"
      ],
      "metadata": {
        "id": "dksEmCgw6GOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is the capital of India?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9qrnl8DmbFy",
        "outputId": "1cdd66b2-f639-4d9a-c576-253253222942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: What is the capital of India?\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Bi-Encoder Retrieval hit\n",
            "Mumbai (previously known as Bombay until 1996) is a natural harbor on the west coast of India, and is the capital city of Maharashtra state. It is India's largest city, and one of the world's most populous cities. It is the financial capital of India. The city is the second most-populous in the world. It has approximately 13 million people. Along with the neighboring cities of Navi Mumbai and Thane, it forms the world's 4th largest urban agglomeration. They have around 19.1 million people.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Cross-Encoder Re-ranker hit\n",
            "New Delhi () is the capital of India and a union territory of the megacity of Delhi. It has a very old history and is home to several monuments where the city is expensive to live in. In traditional Indian geography it falls under the North Indian zone. The city has an area of about 42.7 km. New Delhi has a population of about 9.4 Million people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is natural language processing?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syaODja7SQEW",
        "outputId": "ed54d6e7-5caa-4adb-a535-5803baec1604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: What is natural language processing?\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Bi-Encoder Retrieval hit\n",
            "Natural Language Processing (NLP) is a field in Artificial Intelligence, and is also related to linguistics. On a high level, the goal of NLP is to program computers to automatically understand human languages, and also to automatically write/speak in human languages. We say \"Natural Language\" to mean human language, and to indicate that we are not talking about computer (programming) languages.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Cross-Encoder Re-ranker hit\n",
            "Natural Language Processing (NLP) is a field in Artificial Intelligence, and is also related to linguistics. On a high level, the goal of NLP is to program computers to automatically understand human languages, and also to automatically write/speak in human languages. We say \"Natural Language\" to mean human language, and to indicate that we are not talking about computer (programming) languages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is language?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAhF2d1HZDSC",
        "outputId": "9d7679dd-8b11-4f91-b6de-a06e72361cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: What is language?\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Bi-Encoder Retrieval hit\n",
            "Philosophy of language is the study of how languages were created and are used. It is part of Linguistics. In continental philosophy, it is not treated as a subject by itself, but Ludwig Wittgenstein and other analytic philosophers placed particular stress on it.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Cross-Encoder Re-ranker hit\n",
            "Language is the normal way humans communicate. Only humans use language, though other animals communicate through other means.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is coldest place on earth?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dATCBKJ2eYH",
        "outputId": "67c75afe-5529-481c-ce2a-d6d0155f513e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: What is coldest place on earth?\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Bi-Encoder Retrieval hit\n",
            "East Antarctica, also called Greater Antarctica, is the largest part (two-thirds) of the Antarctic continent. It is on the Indian Ocean side of the Transantarctic Mountains. It is the coldest, windiest, and driest part of Earth. East Antarctica holds the record as the coldest place on earth.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Cross-Encoder Re-ranker hit\n",
            "East Antarctica, also called Greater Antarctica, is the largest part (two-thirds) of the Antarctic continent. It is on the Indian Ocean side of the Transantarctic Mountains. It is the coldest, windiest, and driest part of Earth. East Antarctica holds the record as the coldest place on earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search(query = \"What is the animal which can run very fast?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtY_OjzT2pGC",
        "outputId": "2e6af40b-c5b0-4e26-b0e7-2bdb11a22aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input question: What is the animal which can run very fast?\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Bi-Encoder Retrieval hit\n",
            "Running is the way in which people or animals travel quickly on their feet. It is a method of travelling on land. It is different to walking in that both feet are regularly off the ground at the same time. Different terms are used to refer to running according to the speed: jogging is slow, and sprinting is running fast.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Top Cross-Encoder Re-ranker hit\n",
            "A cheetah (\"Acinonyx jubatus\") is a medium large cat which lives in Africa. It is the fastest land animal and can run up to 112 kilometers per hour for a short time. Most cheetahs live in the savannas of Africa. There are a few in Asia. Cheetahs are active during the day, and hunt in the early morning or late evening.\n"
          ]
        }
      ]
    }
  ]
}