{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanketrk/Clustering-of-Network-Complaint-Data/blob/master/2_Hands_on_Using_ChatGPT_with_Python_and_LangChain_for_real_world_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using ChatGPT with Python and LangChain for real-world tasks\n",
        "\n",
        "In this notebook you will use ChatGPT and LangChain to solve and learn about:\n",
        "\n",
        "- Langchain chains\n",
        "- Memory and conversation chains\n",
        "\n",
        "- Exercise 1: Review Analysis and Response\n",
        "- Exercise 2: Paper Analysis and Summarization\n",
        "\n",
        "\n",
        "Bonus: Build a text-based chatbot\n",
        "\n",
        "___[Created By: Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___"
      ],
      "metadata": {
        "id": "XTzBUFWQ-OWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI and LangChain dependencies"
      ],
      "metadata": {
        "id": "L1KvMtf54l0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install langchain langchain-openai"
      ],
      "metadata": {
        "id": "2evPp14fy258"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load OpenAI API Credentials\n",
        "\n",
        "Here we load it from a file so we don't explore the credentials on the internet by mistake"
      ],
      "metadata": {
        "id": "CiwGjVWK4q6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "5e1HqI56y7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryheOZuXxa41"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "with open('chatgpt_api_credentials.yml', 'r') as file:\n",
        "    api_creds = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_creds.keys()"
      ],
      "metadata": {
        "id": "eZs7ts6NzADJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = api_creds['openai_key']"
      ],
      "metadata": {
        "id": "kDe44J0N0NcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Necessary Dependencies and LLM"
      ],
      "metadata": {
        "id": "VDWhgxCy5bA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "9GYhyRFRuJXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.0)"
      ],
      "metadata": {
        "id": "mY2bapqfuWq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's look at how to create a basic chain"
      ],
      "metadata": {
        "id": "qJrIiENwxMx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
        "chain = (\n",
        "         prompt\n",
        "         |\n",
        "         model\n",
        ")\n",
        "\n",
        "response = chain.invoke({\"topic\": \"bears\"})\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "8Evdag0KuOXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# can be used on multiple prompts also\n",
        "topics = [{'topic': 'AI'}, {'topic': 'Statistics'}]\n",
        "responses = chain.map().invoke(topics)"
      ],
      "metadata": {
        "id": "Tp84pgKXvKuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "QePjecVqviA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic chains are ad-hoc - No conversation history!"
      ],
      "metadata": {
        "id": "jLH8WUaumNMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
        "basic_chain = (\n",
        "               prompt\n",
        "               |\n",
        "              model\n",
        ")"
      ],
      "metadata": {
        "id": "_LZSwWNCx2EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = basic_chain.invoke({\"query\" : 'What are the first four colors of the rainbow?'})\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "ZhvUjj6Vx8QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = basic_chain.invoke({\"query\" : 'And the other three?'})\n",
        "print(response.content) # gives a totally random response"
      ],
      "metadata": {
        "id": "V9nLc6PnySWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's learn how to add memory to build a conversation chain"
      ],
      "metadata": {
        "id": "Y6NeOZe6mZ8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
      ],
      "metadata": {
        "id": "AEQ7Ame0yWwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create prompt template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Act as a helpful AI Assistant\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)"
      ],
      "metadata": {
        "id": "yQliFt8lzdRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({}) # shows the conversation history"
      ],
      "metadata": {
        "id": "ihya5We_RPdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "# creates the conversation chain\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        history=RunnableLambda(memory.load_memory_variables)\n",
        "        |\n",
        "        itemgetter(\"history\")\n",
        "    )\n",
        "    |\n",
        "    prompt\n",
        "    |\n",
        "    model\n",
        ")"
      ],
      "metadata": {
        "id": "66AQdRNaRYYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = {'input': 'What are the first four colors of a rainbow'}\n",
        "response = chain.invoke(user_input)\n",
        "response.content"
      ],
      "metadata": {
        "id": "wfgXhIU-U05R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context(user_input, {\"output\": response.content})\n",
        "memory.load_memory_variables({}) # remembers the conversation history"
      ],
      "metadata": {
        "id": "83bpMrWKVG_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = {'input': 'And the last 3?'}\n",
        "response = chain.invoke(user_input) # uses history of the past conversation to give a better response\n",
        "response.content"
      ],
      "metadata": {
        "id": "7w2ENCJJVjHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context(user_input, {\"output\": response.content})\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "AzGwOdPuVfwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Review Analysis and Response\n",
        "\n",
        "For each review get ChatGPT to do the following and use LLMChain:\n",
        "\n",
        "  - Summarize the review below, delimited by triple\n",
        "  backticks. The summary should be at most 3 lines.\n",
        "  - Highlight both the positives and negatives\n",
        "  - Display the overall sentiment of the review (positive, negative, neutral)\n",
        "  - Display a list of 3 - 5 emotions expressed by the customer in the review\n",
        "  - If the sentiment is positive or neutral write an email and thank them for the review\n",
        "  - If the sentiment is negative apologize and write an email with an appropriate response\n",
        "\n",
        "\n",
        "Remember you can pass the list of documents using the `map().invoke(...)` function with your `chain`"
      ],
      "metadata": {
        "id": "AeDkpvGDhMGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    f\"\"\"\n",
        "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
        "    The sound quality is impressively clear with just the right amount of bass.\n",
        "    It's also waterproof, which tested true during a recent splashing incident.\n",
        "    Though it's compact, the volume can really fill the space.\n",
        "    The price was a bargain for such high-quality sound.\n",
        "    Shipping was also on point, arriving two days early in secure packaging.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Purchased a new gaming keyboard because of its rave reviews about responsiveness and backlighting.\n",
        "    It hasn't disappointed. The keys have a satisfying click and the LED colors are vibrant,\n",
        "    enhancing my gaming experience significantly. Price-wise, it's quite competitive,\n",
        "    and I feel like I got a good deal. The delivery was swift, and it came well-protected,\n",
        "    ensuring no damage during transport.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Ordered a set of wireless earbuds for running, and they've been a letdown.\n",
        "    The sound constantly cuts out, and the fit is uncomfortable after only a few minutes of use.\n",
        "    They advertised a 12-hour battery life, but I'm barely getting four hours.\n",
        "    Considering the cost, I expected better quality and performance.\n",
        "    They did arrive on time, but the positives end there. I'm already looking into a return.\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    The tablet stand I bought was touted as being sturdy and adjustable,\n",
        "    but it's anything but. It wobbles with the slightest touch,\n",
        "    and the angles are not holding up as promised. It feels like a breeze could knock it over.\n",
        "    It was also pricier than others I've seen, which adds to the disappointment.\n",
        "    It did arrive promptly, but what's the use if the product doesn't meet basic expectations?\n",
        "    \"\"\",\n",
        "    f\"\"\"\n",
        "    Needed a new kitchen blender, but this model has been a nightmare.\n",
        "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
        "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
        "    I thought the brand meant quality, but this product has proven me wrong.\n",
        "    Plus, it arrived three days late. Definitely not worth the expense.\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "hRbBZB57hT0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "            Act as a product review analyst.\n",
        "            Your task is to perform the following tasks:\n",
        "\n",
        "            - Summarize the review below, delimited by triple\n",
        "            backticks. The summary should be at most 3 lines.\n",
        "            - Highlight both the positives and negatives\n",
        "            - Display the overall sentiment of the review (positive, negative, neutral)\n",
        "            - Display a list of 3 - 5 emotions expressed by the customer in the review\n",
        "            - If the sentiment is positive or neutral write an email and thank them for the review\n",
        "            - If the sentiment is negative apologize and write an email with an appropriate response\n",
        "\n",
        "            ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "reviews_formatted =\n",
        "prompt_template =\n",
        "llm_chain ="
      ],
      "metadata": {
        "id": "mlkR6kQfhdMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results ="
      ],
      "metadata": {
        "id": "d_oo3lVVFckF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "  print(result.content)\n",
        "  print('-----')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "aWlI8SYRGUM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: Paper Analysis and Summarization\n",
        "\n",
        "- Act as a Artificial Intelligence Expert.\n",
        "Transform this research paper abstract in triple backticks\n",
        "into a short concise version of maximum 10 lines for your audience.\n",
        "\n",
        "- Act as a Artificial Intelligence Expert.\n",
        "Transform this research paper abstract in triple backticks\n",
        "into an executive summary for a healthcare company.\n",
        "Have bullet points for pros and cons of ethics in Generative AI as mentioned in the paper.\n",
        "\n",
        "- Act as a Artificial Intelligence Expert.\n",
        "Transform this research paper abstract in triple backticks\n",
        "into an executive summary for a generative AI company solving healthcare problems.\n",
        "Have bullet points for key points mentioned for\n",
        "Generative AI for text, images and structured data based healthcare\n",
        "\n",
        "Use Conversation Chains with `ConversationBufferMemory` and modify ChatGPT behavior with System prompts as necessary to do the above 3"
      ],
      "metadata": {
        "id": "eEtB1IOimA0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper_abstract = f\"\"\"\n",
        "The widespread use of ChatGPT and other emerging technology powered by generative\n",
        "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
        "high-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\n",
        "issues beyond following guidelines and regulations that are still under discussion and\n",
        "development. On the other hand, other types of generative AI have been used to synthesize\n",
        "images and other types of data for research and practical purposes, which have resolved some\n",
        "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
        "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
        "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
        "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
        "transparent documentation of ethical discussions in generative AI development. While the\n",
        "checklist can be readily integrated into the current peer review and publication system to\n",
        "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
        "products) to help users establish reasonable trust in their capabilities.\n",
        "\n",
        "Current ethical discussions on generative AI in healthcare\n",
        "We conducted a systematic scoping review to analyse current ethical discussions on\n",
        "generative AI in healthcare. Our search in four major academic research databases for\n",
        "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
        "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
        "which 193 articles were included for analysis based on application data modality (text, image,\n",
        "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
        "AI causes or offers technical solutions for issues raised.\n",
        "\n",
        "Generative AI for text data-based healthcare\n",
        "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
        "applications for text data, with 20 articles describing methodological developments or\n",
        "applications of generative AI and the other 21 articles describing review-type works on this\n",
        "topic. Although some of these review-type articles used the general term “generative AI”, the\n",
        "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
        "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
        "ethical aspects.\n",
        "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
        "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
        "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
        "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
        "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
        "on the need for ethical considerations in LLMs and is summarised in the “Others” category.\n",
        "Although all ethical principles are equally important, some are discussed more often than\n",
        "others, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\n",
        "privacy.\n",
        "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
        "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
        "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
        "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
        "health-related misinformation, to generate trusted content, and to improve accountability or\n",
        "transparency over existing approaches. While most articles focused on either identifying\n",
        "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
        "articles discussed both to provide a more balanced perspective.\n",
        "\n",
        "Generative AI for image and structured data-based healthcare\n",
        "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
        "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
        "majority of articles discussed the methodological developments of generative AI as giving\n",
        "rise to a more distinctive and focused set of ethical issues.\n",
        "5\n",
        "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
        "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
        "brief motivation for methodological developments or as a general discussion point. The rest\n",
        "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
        "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
        "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
        "article24 discussed detailed ethical concerns on generative AI applications.\n",
        "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
        "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
        "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
        "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
        "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
        "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
        "additionally lacked discussions on trust or transparency.\n",
        "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
        "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
        "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
        "generative AI. Only two articles on structured data included both the cause and resolving\n",
        "perspectives by discussing ethical issues that may arise from limitations of methods\n",
        "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4FnITE6zhV-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYS_PROMPT = \"\"\"\n",
        "Act as a Artificial Intelligence Expert.\n",
        "Transform the input research paper abstract in triple backticks\n",
        "based on the audience input by the user.\n",
        "\"\"\"\n",
        "prompt =\n",
        "\n",
        "memory =\n",
        "\n",
        "conversation_chain ="
      ],
      "metadata": {
        "id": "E5S9fvwrYZ6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Transform this research paper abstract\n",
        "into a short concise version of\n",
        "maximum 10 lines for your audience.\n",
        "Output summary should not have triple backticks.\n",
        "\n",
        "\n",
        "Abstract:\n",
        "```{paper_abstract}```\n",
        "\"\"\"\n",
        "user_instruction =\n",
        "response =\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "L8cgurf6Ytds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save conversation to memory\n",
        "memory.save_context(user_instruction, {\"output\": response.content})"
      ],
      "metadata": {
        "id": "wjRlutKEaUwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Now build an executive summary for a healthcare company.\n",
        "Have bullet points for pros and cons of ethics in Generative AI\n",
        "as mentioned in the paper earlier.\n",
        "\"\"\"\n",
        "\n",
        "user_instruction =\n",
        "response =\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "luJsKw9IkEtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save conversation to memory\n",
        "memory.save_context(user_instruction, {\"output\": response.content})"
      ],
      "metadata": {
        "id": "RvcAf6ZceV4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Now build an executive summary for a generative AI company solving healthcare problems.\n",
        "Have bullet points for key points mentioned for\n",
        "Generative AI for text, images and structured data based healthcare\n",
        "\"\"\"\n",
        "\n",
        "user_instruction =\n",
        "response =\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "fUjMVo63eZit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BONUS: Build a Conversational Chatbot"
      ],
      "metadata": {
        "id": "xEtKuq9KntCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary components from the LangChain library.\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "def run_chatgpt_chatbot(system_prompt='', history_window=30, temperature=0.3):\n",
        "\n",
        "  model = ChatOpenAI(model_name='gpt-3.5-turbo',\n",
        "                     temperature=temperature)\n",
        "\n",
        "  if system_prompt:\n",
        "    SYS_PROMPT = system_prompt\n",
        "  else:\n",
        "    SYS_PROMPT = \"\"\"\n",
        "                  Act as a helpful AI Assistant\n",
        "                 \"\"\"\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\"system\", SYS_PROMPT),\n",
        "          MessagesPlaceholder(variable_name=\"history\"),\n",
        "          (\"human\", \"{input}\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  memory = ConversationBufferWindowMemory(k=history_window,\n",
        "                                          return_messages=True)\n",
        "\n",
        "  conversation_chain = (\n",
        "      RunnablePassthrough.assign(\n",
        "          history=RunnableLambda(memory.load_memory_variables)\n",
        "          |\n",
        "          itemgetter(\"history\")\n",
        "      )\n",
        "      |\n",
        "      prompt\n",
        "      |\n",
        "      model\n",
        "  )\n",
        "\n",
        "  # Print a welcome message when the chatbot starts.\n",
        "  print(\"Hello! I am your friendly chatbot. Let's chat! (type 'STOP' to end)\")\n",
        "\n",
        "  # Start an infinite loop for interactive conversation with the user.\n",
        "  while True:\n",
        "    # Get input from the user.\n",
        "    prompt = input('User: >>> ')\n",
        "    # Check if the user wants to end the chat.\n",
        "    if prompt.strip().upper() == 'STOP':\n",
        "      print(\"ChatGPT: >>> Goodbye!\")\n",
        "      break\n",
        "\n",
        "    # Generate and print the chatbot's reply.\n",
        "    user_inp = {'input': prompt}\n",
        "    reply = conversation_chain.invoke(user_inp)\n",
        "    print(f\"ChatGPT: >>>\\n{reply.content}\")\n",
        "    memory.save_context(user_inp, {\"output\": reply.content})"
      ],
      "metadata": {
        "id": "LzLp_Fqme2u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_chatgpt_chatbot()"
      ],
      "metadata": {
        "id": "0UdH6mtTio_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_chatgpt_chatbot(system_prompt='Act as a sarcastic child')"
      ],
      "metadata": {
        "id": "5peyF0v8kBVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acBKCMfoip3z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}